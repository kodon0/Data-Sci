{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook uses the MNIST clothing data set to use CNNs - 10 labels for 28x28 grayscale clothing images\n",
    "# The training set of 60,000 images and 10,000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f91e7119f90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Looking at an image\n",
    "plt.imshow(x_train[12], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's a sandal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising the data range\n",
    "\n",
    "x_train = x_train/x_train.max()\n",
    "x_test = x_test/x_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data - 4 channels\n",
    "x_train = x_train.reshape(60000,28,28,1)\n",
    "x_test = x_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding y_train and y_test -> 10 labels\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_cat_test = to_categorical(y_test,10)\n",
    "y_cat_train = to_categorical(y_train,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 25, 25, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 591,786\n",
      "Trainable params: 591,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model defintion\n",
    "\n",
    "model = Sequential()\n",
    "# Conv layer\n",
    "model.add(Conv2D(filters=32, kernel_size = (4,4),input_shape=(28,28,1), activation = 'relu'))\n",
    "# Pooling layer\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "# Flatten 2D to 1D\n",
    "model.add(Flatten())\n",
    "# Dense layer\n",
    "model.add(Dense(128,activation='relu'))\n",
    "# Output classifier\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "# Compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer ='rmsprop',\n",
    "             metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 35s 584us/step - loss: 0.3933 - accuracy: 0.8610\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 33s 545us/step - loss: 0.2775 - accuracy: 0.9003\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 33s 558us/step - loss: 0.2396 - accuracy: 0.9133\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 32s 540us/step - loss: 0.2164 - accuracy: 0.9231\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 25s 419us/step - loss: 0.1992 - accuracy: 0.9295\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 27s 456us/step - loss: 0.1848 - accuracy: 0.9343\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 28s 472us/step - loss: 0.1734 - accuracy: 0.9384\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 27s 451us/step - loss: 0.1635 - accuracy: 0.9428\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 31s 517us/step - loss: 0.1536 - accuracy: 0.9454\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 26s 429us/step - loss: 0.1465 - accuracy: 0.9481\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 29s 491us/step - loss: 0.1387 - accuracy: 0.9510\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 27s 457us/step - loss: 0.1310 - accuracy: 0.9543\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 27s 457us/step - loss: 0.1243 - accuracy: 0.9564\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 27s 444us/step - loss: 0.1172 - accuracy: 0.9592\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.1112 - accuracy: 0.9628\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 26s 427us/step - loss: 0.1064 - accuracy: 0.9635\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 29s 482us/step - loss: 0.0996 - accuracy: 0.9661\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.0949 - accuracy: 0.9678\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 27s 445us/step - loss: 0.0908 - accuracy: 0.9685\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 27s 458us/step - loss: 0.0855 - accuracy: 0.9710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f91e09daa50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "model.fit(x_train,y_cat_train, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 119us/step\n",
      "[0.4765019508481026, 0.9028000235557556]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "\n",
    "model.metrics_names\n",
    "print(model.evaluate(x_test,y_cat_test))\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85      1000\n",
      "           1       0.98      0.98      0.98      1000\n",
      "           2       0.82      0.88      0.85      1000\n",
      "           3       0.91      0.91      0.91      1000\n",
      "           4       0.83      0.83      0.83      1000\n",
      "           5       0.98      0.96      0.97      1000\n",
      "           6       0.78      0.68      0.73      1000\n",
      "           7       0.95      0.97      0.96      1000\n",
      "           8       0.97      0.97      0.97      1000\n",
      "           9       0.96      0.97      0.96      1000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
