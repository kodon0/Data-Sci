{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.247e+01, 1.860e+01, 8.109e+01, ..., 1.015e-01, 3.014e-01,\n",
       "        8.750e-02],\n",
       "       [1.894e+01, 2.131e+01, 1.236e+02, ..., 1.789e-01, 2.551e-01,\n",
       "        6.589e-02],\n",
       "       [1.546e+01, 1.948e+01, 1.017e+02, ..., 1.514e-01, 2.837e-01,\n",
       "        8.019e-02],\n",
       "       ...,\n",
       "       [1.371e+01, 2.083e+01, 9.020e+01, ..., 1.556e-01, 3.196e-01,\n",
       "        1.151e-01],\n",
       "       [1.447e+01, 2.499e+01, 9.581e+01, ..., 1.205e-01, 3.187e-01,\n",
       "        1.023e-01],\n",
       "       [1.354e+01, 1.436e+01, 8.746e+01, ..., 1.288e-01, 2.977e-01,\n",
       "        7.259e-02]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 381, 1)            31        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build using TFlow\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units = 1, input_shape = X_train.shape, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'adam', metrics = ['accuracy'],loss = 'binary_crossentropy')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 381, 30) for input Tensor(\"dense_19_input:0\", shape=(None, 381, 30), dtype=float32), but it was called on an input with incompatible shape (None, 30).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 381, 30) for input Tensor(\"dense_19_input:0\", shape=(None, 381, 30), dtype=float32), but it was called on an input with incompatible shape (None, 30).\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.5703 - accuracy: 0.6562WARNING:tensorflow:Model was constructed with shape (None, 381, 30) for input Tensor(\"dense_19_input:0\", shape=(None, 381, 30), dtype=float32), but it was called on an input with incompatible shape (None, 30).\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6383 - accuracy: 0.6614 - val_loss: 0.6103 - val_accuracy: 0.6277\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5725 - accuracy: 0.7270 - val_loss: 0.5506 - val_accuracy: 0.7340\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5180 - accuracy: 0.7743 - val_loss: 0.5000 - val_accuracy: 0.7872\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4706 - accuracy: 0.7979 - val_loss: 0.4591 - val_accuracy: 0.8351\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.8373 - val_loss: 0.4240 - val_accuracy: 0.8670\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.8609 - val_loss: 0.3957 - val_accuracy: 0.8883\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8845 - val_loss: 0.3717 - val_accuracy: 0.8936\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3526 - accuracy: 0.8924 - val_loss: 0.3512 - val_accuracy: 0.8936\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3332 - accuracy: 0.8950 - val_loss: 0.3335 - val_accuracy: 0.9043\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3164 - accuracy: 0.8924 - val_loss: 0.3178 - val_accuracy: 0.9202\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3013 - accuracy: 0.9003 - val_loss: 0.3045 - val_accuracy: 0.9255\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2882 - accuracy: 0.9081 - val_loss: 0.2924 - val_accuracy: 0.9255\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2768 - accuracy: 0.9081 - val_loss: 0.2812 - val_accuracy: 0.9202\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2660 - accuracy: 0.9186 - val_loss: 0.2714 - val_accuracy: 0.9255\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2566 - accuracy: 0.9213 - val_loss: 0.2624 - val_accuracy: 0.9309\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2480 - accuracy: 0.9291 - val_loss: 0.2542 - val_accuracy: 0.9309\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2400 - accuracy: 0.9291 - val_loss: 0.2468 - val_accuracy: 0.9309\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2330 - accuracy: 0.9318 - val_loss: 0.2398 - val_accuracy: 0.9309\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2264 - accuracy: 0.9344 - val_loss: 0.2333 - val_accuracy: 0.9309\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2202 - accuracy: 0.9396 - val_loss: 0.2272 - val_accuracy: 0.9362\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2145 - accuracy: 0.9423 - val_loss: 0.2216 - val_accuracy: 0.9362\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2091 - accuracy: 0.9449 - val_loss: 0.2165 - val_accuracy: 0.9362\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2044 - accuracy: 0.9501 - val_loss: 0.2114 - val_accuracy: 0.9362\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1996 - accuracy: 0.9554 - val_loss: 0.2068 - val_accuracy: 0.9415\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1953 - accuracy: 0.9554 - val_loss: 0.2025 - val_accuracy: 0.9415\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1912 - accuracy: 0.9580 - val_loss: 0.1983 - val_accuracy: 0.9415\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1875 - accuracy: 0.9580 - val_loss: 0.1943 - val_accuracy: 0.9468\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1837 - accuracy: 0.9606 - val_loss: 0.1907 - val_accuracy: 0.9521\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1803 - accuracy: 0.9606 - val_loss: 0.1872 - val_accuracy: 0.9521\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1771 - accuracy: 0.9633 - val_loss: 0.1838 - val_accuracy: 0.9521\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1740 - accuracy: 0.9633 - val_loss: 0.1806 - val_accuracy: 0.9521\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1711 - accuracy: 0.9633 - val_loss: 0.1776 - val_accuracy: 0.9521\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1683 - accuracy: 0.9659 - val_loss: 0.1747 - val_accuracy: 0.9521\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1657 - accuracy: 0.9659 - val_loss: 0.1718 - val_accuracy: 0.9521\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1631 - accuracy: 0.9685 - val_loss: 0.1690 - val_accuracy: 0.9521\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1607 - accuracy: 0.9685 - val_loss: 0.1665 - val_accuracy: 0.9521\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1584 - accuracy: 0.9685 - val_loss: 0.1640 - val_accuracy: 0.9521\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1562 - accuracy: 0.9685 - val_loss: 0.1616 - val_accuracy: 0.9521\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1541 - accuracy: 0.9685 - val_loss: 0.1593 - val_accuracy: 0.9521\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1520 - accuracy: 0.9685 - val_loss: 0.1571 - val_accuracy: 0.9521\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1501 - accuracy: 0.9685 - val_loss: 0.1550 - val_accuracy: 0.9521\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1483 - accuracy: 0.9685 - val_loss: 0.1529 - val_accuracy: 0.9521\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1464 - accuracy: 0.9685 - val_loss: 0.1509 - val_accuracy: 0.9574\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1447 - accuracy: 0.9685 - val_loss: 0.1490 - val_accuracy: 0.9574\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1431 - accuracy: 0.9685 - val_loss: 0.1471 - val_accuracy: 0.9574\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1414 - accuracy: 0.9685 - val_loss: 0.1454 - val_accuracy: 0.9574\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1399 - accuracy: 0.9685 - val_loss: 0.1436 - val_accuracy: 0.9574\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1384 - accuracy: 0.9685 - val_loss: 0.1419 - val_accuracy: 0.9574\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1369 - accuracy: 0.9685 - val_loss: 0.1404 - val_accuracy: 0.9574\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1356 - accuracy: 0.9685 - val_loss: 0.1387 - val_accuracy: 0.9628\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1342 - accuracy: 0.9685 - val_loss: 0.1373 - val_accuracy: 0.9628\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1329 - accuracy: 0.9685 - val_loss: 0.1358 - val_accuracy: 0.9628\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1316 - accuracy: 0.9685 - val_loss: 0.1343 - val_accuracy: 0.9628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1304 - accuracy: 0.9685 - val_loss: 0.1330 - val_accuracy: 0.9628\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1293 - accuracy: 0.9685 - val_loss: 0.1316 - val_accuracy: 0.9628\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1280 - accuracy: 0.9685 - val_loss: 0.1303 - val_accuracy: 0.9628\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1270 - accuracy: 0.9711 - val_loss: 0.1290 - val_accuracy: 0.9628\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1259 - accuracy: 0.9711 - val_loss: 0.1277 - val_accuracy: 0.9628\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1249 - accuracy: 0.9711 - val_loss: 0.1265 - val_accuracy: 0.9628\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1238 - accuracy: 0.9711 - val_loss: 0.1253 - val_accuracy: 0.9628\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1228 - accuracy: 0.9711 - val_loss: 0.1241 - val_accuracy: 0.9628\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1219 - accuracy: 0.9711 - val_loss: 0.1231 - val_accuracy: 0.9628\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1209 - accuracy: 0.9711 - val_loss: 0.1220 - val_accuracy: 0.9628\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1200 - accuracy: 0.9711 - val_loss: 0.1209 - val_accuracy: 0.9628\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1191 - accuracy: 0.9711 - val_loss: 0.1199 - val_accuracy: 0.9628\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1183 - accuracy: 0.9711 - val_loss: 0.1188 - val_accuracy: 0.9681\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1174 - accuracy: 0.9711 - val_loss: 0.1178 - val_accuracy: 0.9681\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9711 - val_loss: 0.1169 - val_accuracy: 0.9681\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1158 - accuracy: 0.9711 - val_loss: 0.1159 - val_accuracy: 0.9734\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1150 - accuracy: 0.9711 - val_loss: 0.1150 - val_accuracy: 0.9734\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1142 - accuracy: 0.9711 - val_loss: 0.1141 - val_accuracy: 0.9734\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1135 - accuracy: 0.9711 - val_loss: 0.1132 - val_accuracy: 0.9734\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1128 - accuracy: 0.9711 - val_loss: 0.1124 - val_accuracy: 0.9734\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1121 - accuracy: 0.9711 - val_loss: 0.1116 - val_accuracy: 0.9734\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1114 - accuracy: 0.9711 - val_loss: 0.1107 - val_accuracy: 0.9734\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1107 - accuracy: 0.9711 - val_loss: 0.1099 - val_accuracy: 0.9734\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1100 - accuracy: 0.9711 - val_loss: 0.1091 - val_accuracy: 0.9734\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1094 - accuracy: 0.9711 - val_loss: 0.1083 - val_accuracy: 0.9734\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1087 - accuracy: 0.9711 - val_loss: 0.1075 - val_accuracy: 0.9734\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1081 - accuracy: 0.9711 - val_loss: 0.1069 - val_accuracy: 0.9734\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1075 - accuracy: 0.9738 - val_loss: 0.1061 - val_accuracy: 0.9734\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1069 - accuracy: 0.9738 - val_loss: 0.1054 - val_accuracy: 0.9734\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1064 - accuracy: 0.9738 - val_loss: 0.1047 - val_accuracy: 0.9734\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.9738 - val_loss: 0.1040 - val_accuracy: 0.9734\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1052 - accuracy: 0.9738 - val_loss: 0.1033 - val_accuracy: 0.9734\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1046 - accuracy: 0.9738 - val_loss: 0.1027 - val_accuracy: 0.9734\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1041 - accuracy: 0.9738 - val_loss: 0.1020 - val_accuracy: 0.9734\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.9764 - val_loss: 0.1014 - val_accuracy: 0.9734\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1030 - accuracy: 0.9764 - val_loss: 0.1008 - val_accuracy: 0.9734\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1026 - accuracy: 0.9764 - val_loss: 0.1002 - val_accuracy: 0.9734\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1020 - accuracy: 0.9764 - val_loss: 0.0996 - val_accuracy: 0.9787\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1016 - accuracy: 0.9790 - val_loss: 0.0990 - val_accuracy: 0.9787\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1011 - accuracy: 0.9790 - val_loss: 0.0984 - val_accuracy: 0.9787\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1006 - accuracy: 0.9790 - val_loss: 0.0979 - val_accuracy: 0.9840\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1002 - accuracy: 0.9790 - val_loss: 0.0973 - val_accuracy: 0.9840\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0998 - accuracy: 0.9790 - val_loss: 0.0967 - val_accuracy: 0.9840\n",
      "Epoch 97/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.9790 - val_loss: 0.0963 - val_accuracy: 0.9840\n",
      "Epoch 98/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0988 - accuracy: 0.9790 - val_loss: 0.0957 - val_accuracy: 0.9840\n",
      "Epoch 99/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0984 - accuracy: 0.9790 - val_loss: 0.0952 - val_accuracy: 0.9840\n",
      "Epoch 100/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0979 - accuracy: 0.9790 - val_loss: 0.0947 - val_accuracy: 0.9840\n",
      "Epoch 101/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0975 - accuracy: 0.9790 - val_loss: 0.0942 - val_accuracy: 0.9840\n",
      "Epoch 102/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0971 - accuracy: 0.9790 - val_loss: 0.0937 - val_accuracy: 0.9840\n",
      "Epoch 103/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0967 - accuracy: 0.9790 - val_loss: 0.0932 - val_accuracy: 0.9840\n",
      "Epoch 104/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9790 - val_loss: 0.0928 - val_accuracy: 0.9840\n",
      "Epoch 105/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9790 - val_loss: 0.0923 - val_accuracy: 0.9840\n",
      "Epoch 106/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9790 - val_loss: 0.0918 - val_accuracy: 0.9840\n",
      "Epoch 107/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0952 - accuracy: 0.9790 - val_loss: 0.0913 - val_accuracy: 0.9840\n",
      "Epoch 108/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0948 - accuracy: 0.9790 - val_loss: 0.0909 - val_accuracy: 0.9840\n",
      "Epoch 109/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0944 - accuracy: 0.9790 - val_loss: 0.0905 - val_accuracy: 0.9840\n",
      "Epoch 110/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0941 - accuracy: 0.9790 - val_loss: 0.0901 - val_accuracy: 0.9840\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0937 - accuracy: 0.9790 - val_loss: 0.0897 - val_accuracy: 0.9840\n",
      "Epoch 112/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0934 - accuracy: 0.9790 - val_loss: 0.0892 - val_accuracy: 0.9840\n",
      "Epoch 113/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.9790 - val_loss: 0.0888 - val_accuracy: 0.9840\n",
      "Epoch 114/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0927 - accuracy: 0.9790 - val_loss: 0.0884 - val_accuracy: 0.9840\n",
      "Epoch 115/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0923 - accuracy: 0.9790 - val_loss: 0.0880 - val_accuracy: 0.9840\n",
      "Epoch 116/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0920 - accuracy: 0.9790 - val_loss: 0.0876 - val_accuracy: 0.9840\n",
      "Epoch 117/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0917 - accuracy: 0.9790 - val_loss: 0.0873 - val_accuracy: 0.9840\n",
      "Epoch 118/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0914 - accuracy: 0.9790 - val_loss: 0.0868 - val_accuracy: 0.9840\n",
      "Epoch 119/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0910 - accuracy: 0.9790 - val_loss: 0.0865 - val_accuracy: 0.9840\n",
      "Epoch 120/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0907 - accuracy: 0.9790 - val_loss: 0.0861 - val_accuracy: 0.9840\n",
      "Epoch 121/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.9790 - val_loss: 0.0858 - val_accuracy: 0.9840\n",
      "Epoch 122/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0901 - accuracy: 0.9790 - val_loss: 0.0854 - val_accuracy: 0.9840\n",
      "Epoch 123/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0898 - accuracy: 0.9790 - val_loss: 0.0851 - val_accuracy: 0.9840\n",
      "Epoch 124/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0895 - accuracy: 0.9790 - val_loss: 0.0847 - val_accuracy: 0.9840\n",
      "Epoch 125/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0893 - accuracy: 0.9790 - val_loss: 0.0844 - val_accuracy: 0.9840\n",
      "Epoch 126/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0889 - accuracy: 0.9790 - val_loss: 0.0841 - val_accuracy: 0.9840\n",
      "Epoch 127/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0887 - accuracy: 0.9790 - val_loss: 0.0837 - val_accuracy: 0.9840\n",
      "Epoch 128/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 0.9790 - val_loss: 0.0834 - val_accuracy: 0.9840\n",
      "Epoch 129/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0881 - accuracy: 0.9790 - val_loss: 0.0831 - val_accuracy: 0.9840\n",
      "Epoch 130/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0878 - accuracy: 0.9790 - val_loss: 0.0828 - val_accuracy: 0.9840\n",
      "Epoch 131/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9790 - val_loss: 0.0824 - val_accuracy: 0.9840\n",
      "Epoch 132/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0873 - accuracy: 0.9790 - val_loss: 0.0821 - val_accuracy: 0.9840\n",
      "Epoch 133/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.9790 - val_loss: 0.0818 - val_accuracy: 0.9840\n",
      "Epoch 134/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0867 - accuracy: 0.9790 - val_loss: 0.0815 - val_accuracy: 0.9840\n",
      "Epoch 135/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 0.9790 - val_loss: 0.0812 - val_accuracy: 0.9840\n",
      "Epoch 136/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0862 - accuracy: 0.9790 - val_loss: 0.0809 - val_accuracy: 0.9840\n",
      "Epoch 137/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0860 - accuracy: 0.9790 - val_loss: 0.0806 - val_accuracy: 0.9840\n",
      "Epoch 138/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0857 - accuracy: 0.9790 - val_loss: 0.0804 - val_accuracy: 0.9840\n",
      "Epoch 139/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0855 - accuracy: 0.9790 - val_loss: 0.0801 - val_accuracy: 0.9840\n",
      "Epoch 140/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0853 - accuracy: 0.9790 - val_loss: 0.0798 - val_accuracy: 0.9840\n",
      "Epoch 141/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0851 - accuracy: 0.9790 - val_loss: 0.0795 - val_accuracy: 0.9840\n",
      "Epoch 142/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0848 - accuracy: 0.9790 - val_loss: 0.0792 - val_accuracy: 0.9840\n",
      "Epoch 143/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0845 - accuracy: 0.9790 - val_loss: 0.0790 - val_accuracy: 0.9840\n",
      "Epoch 144/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0843 - accuracy: 0.9790 - val_loss: 0.0787 - val_accuracy: 0.9840\n",
      "Epoch 145/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0841 - accuracy: 0.9790 - val_loss: 0.0785 - val_accuracy: 0.9840\n",
      "Epoch 146/200\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0838 - accuracy: 0.9790 - val_loss: 0.0782 - val_accuracy: 0.9840\n",
      "Epoch 147/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0836 - accuracy: 0.9790 - val_loss: 0.0780 - val_accuracy: 0.9840\n",
      "Epoch 148/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0834 - accuracy: 0.9790 - val_loss: 0.0777 - val_accuracy: 0.9840\n",
      "Epoch 149/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9790 - val_loss: 0.0774 - val_accuracy: 0.9840\n",
      "Epoch 150/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 0.9790 - val_loss: 0.0772 - val_accuracy: 0.9840\n",
      "Epoch 151/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0828 - accuracy: 0.9816 - val_loss: 0.0770 - val_accuracy: 0.9840\n",
      "Epoch 152/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0826 - accuracy: 0.9790 - val_loss: 0.0767 - val_accuracy: 0.9840\n",
      "Epoch 153/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9790 - val_loss: 0.0765 - val_accuracy: 0.9840\n",
      "Epoch 154/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0821 - accuracy: 0.9816 - val_loss: 0.0762 - val_accuracy: 0.9840\n",
      "Epoch 155/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0819 - accuracy: 0.9816 - val_loss: 0.0760 - val_accuracy: 0.9840\n",
      "Epoch 156/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0818 - accuracy: 0.9816 - val_loss: 0.0758 - val_accuracy: 0.9840\n",
      "Epoch 157/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0815 - accuracy: 0.9816 - val_loss: 0.0756 - val_accuracy: 0.9840\n",
      "Epoch 158/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0813 - accuracy: 0.9816 - val_loss: 0.0754 - val_accuracy: 0.9840\n",
      "Epoch 159/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.9816 - val_loss: 0.0752 - val_accuracy: 0.9840\n",
      "Epoch 160/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0809 - accuracy: 0.9816 - val_loss: 0.0750 - val_accuracy: 0.9840\n",
      "Epoch 161/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9816 - val_loss: 0.0747 - val_accuracy: 0.9840\n",
      "Epoch 162/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.9816 - val_loss: 0.0745 - val_accuracy: 0.9840\n",
      "Epoch 163/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.9816 - val_loss: 0.0743 - val_accuracy: 0.9840\n",
      "Epoch 164/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0802 - accuracy: 0.9816 - val_loss: 0.0741 - val_accuracy: 0.9840\n",
      "Epoch 165/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0800 - accuracy: 0.9816 - val_loss: 0.0739 - val_accuracy: 0.9840\n",
      "Epoch 166/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0798 - accuracy: 0.9816 - val_loss: 0.0737 - val_accuracy: 0.9840\n",
      "Epoch 167/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0796 - accuracy: 0.9816 - val_loss: 0.0735 - val_accuracy: 0.9840\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.9816 - val_loss: 0.0733 - val_accuracy: 0.9840\n",
      "Epoch 169/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0793 - accuracy: 0.9816 - val_loss: 0.0731 - val_accuracy: 0.9840\n",
      "Epoch 170/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9816 - val_loss: 0.0729 - val_accuracy: 0.9840\n",
      "Epoch 171/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9816 - val_loss: 0.0727 - val_accuracy: 0.9840\n",
      "Epoch 172/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9816 - val_loss: 0.0725 - val_accuracy: 0.9840\n",
      "Epoch 173/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9816 - val_loss: 0.0723 - val_accuracy: 0.9840\n",
      "Epoch 174/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0784 - accuracy: 0.9816 - val_loss: 0.0722 - val_accuracy: 0.9840\n",
      "Epoch 175/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9816 - val_loss: 0.0720 - val_accuracy: 0.9840\n",
      "Epoch 176/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0781 - accuracy: 0.9816 - val_loss: 0.0718 - val_accuracy: 0.9840\n",
      "Epoch 177/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0779 - accuracy: 0.9816 - val_loss: 0.0717 - val_accuracy: 0.9840\n",
      "Epoch 178/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0778 - accuracy: 0.9816 - val_loss: 0.0715 - val_accuracy: 0.9894\n",
      "Epoch 179/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0776 - accuracy: 0.9816 - val_loss: 0.0713 - val_accuracy: 0.9894\n",
      "Epoch 180/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0774 - accuracy: 0.9816 - val_loss: 0.0711 - val_accuracy: 0.9894\n",
      "Epoch 181/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0772 - accuracy: 0.9816 - val_loss: 0.0709 - val_accuracy: 0.9894\n",
      "Epoch 182/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 0.9816 - val_loss: 0.0708 - val_accuracy: 0.9894\n",
      "Epoch 183/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0769 - accuracy: 0.9816 - val_loss: 0.0706 - val_accuracy: 0.9894\n",
      "Epoch 184/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0768 - accuracy: 0.9816 - val_loss: 0.0705 - val_accuracy: 0.9894\n",
      "Epoch 185/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0767 - accuracy: 0.9816 - val_loss: 0.0702 - val_accuracy: 0.9894\n",
      "Epoch 186/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.9816 - val_loss: 0.0701 - val_accuracy: 0.9894\n",
      "Epoch 187/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0763 - accuracy: 0.9816 - val_loss: 0.0700 - val_accuracy: 0.9894\n",
      "Epoch 188/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0761 - accuracy: 0.9816 - val_loss: 0.0698 - val_accuracy: 0.9894\n",
      "Epoch 189/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9816 - val_loss: 0.0696 - val_accuracy: 0.9894\n",
      "Epoch 190/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0759 - accuracy: 0.9816 - val_loss: 0.0695 - val_accuracy: 0.9894\n",
      "Epoch 191/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0757 - accuracy: 0.9816 - val_loss: 0.0693 - val_accuracy: 0.9894\n",
      "Epoch 192/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 0.9816 - val_loss: 0.0692 - val_accuracy: 0.9894\n",
      "Epoch 193/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9816 - val_loss: 0.0690 - val_accuracy: 0.9894\n",
      "Epoch 194/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0752 - accuracy: 0.9816 - val_loss: 0.0689 - val_accuracy: 0.9894\n",
      "Epoch 195/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0751 - accuracy: 0.9816 - val_loss: 0.0687 - val_accuracy: 0.9894\n",
      "Epoch 196/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 0.9816 - val_loss: 0.0686 - val_accuracy: 0.9894\n",
      "Epoch 197/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9816 - val_loss: 0.0685 - val_accuracy: 0.9894\n",
      "Epoch 198/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.9816 - val_loss: 0.0683 - val_accuracy: 0.9894\n",
      "Epoch 199/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0746 - accuracy: 0.9816 - val_loss: 0.0682 - val_accuracy: 0.9894\n",
      "Epoch 200/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0744 - accuracy: 0.9816 - val_loss: 0.0680 - val_accuracy: 0.9894\n"
     ]
    }
   ],
   "source": [
    "classifier = model.fit(X_train, y_train, epochs = 200, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0784 - accuracy: 0.9843\n",
      "The training loss is:  [0.07844420522451401, 0.9842519760131836]\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9894\n",
      "The test loss is:  [0.0682644471526146, 0.9893617033958435]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "\n",
    "print(\"The training loss is: \", model.evaluate(X_train,y_train))\n",
    "print(\"The test loss is: \", model.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff517a22890>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting evaluations - losses\n",
    "\n",
    "plt.plot(classifier.history['loss'], label = 'loss')\n",
    "plt.plot(classifier.history['val_loss'], label = 'validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff517a78790>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting evaluations - accuracy\n",
    "\n",
    "plt.plot(classifier.history['accuracy'], label = 'accuracy')\n",
    "plt.plot(classifier.history['val_accuracy'], label = 'validation accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.8971722e-01]\n",
      " [3.9333105e-04]\n",
      " [1.7293960e-02]\n",
      " [9.9676895e-01]\n",
      " [9.9950218e-01]\n",
      " [6.8301187e-09]\n",
      " [4.6883710e-07]\n",
      " [1.0860258e-01]\n",
      " [5.1864600e-01]\n",
      " [9.9618506e-01]\n",
      " [9.1907442e-01]\n",
      " [4.0606737e-02]\n",
      " [9.7999835e-01]\n",
      " [3.9878398e-01]\n",
      " [9.9426353e-01]\n",
      " [2.6574731e-03]\n",
      " [9.9266464e-01]\n",
      " [9.9988353e-01]\n",
      " [9.9999750e-01]\n",
      " [4.3622687e-05]\n",
      " [8.6587226e-01]\n",
      " [9.7508568e-01]\n",
      " [4.8988335e-07]\n",
      " [9.9979311e-01]\n",
      " [9.9549294e-01]\n",
      " [9.9817538e-01]\n",
      " [9.9305004e-01]\n",
      " [9.7168863e-01]\n",
      " [9.8914075e-01]\n",
      " [8.9177607e-05]\n",
      " [9.9764091e-01]\n",
      " [9.9936795e-01]\n",
      " [9.9759269e-01]\n",
      " [9.8991430e-01]\n",
      " [9.9951017e-01]\n",
      " [9.9545586e-01]\n",
      " [1.8886766e-01]\n",
      " [9.9602032e-01]\n",
      " [1.1805296e-03]\n",
      " [9.1831362e-01]\n",
      " [9.9952126e-01]\n",
      " [6.9715083e-03]\n",
      " [9.8861337e-01]\n",
      " [9.9705338e-01]\n",
      " [9.5395029e-01]\n",
      " [9.5815700e-01]\n",
      " [9.9905479e-01]\n",
      " [9.9913007e-01]\n",
      " [9.4814146e-01]\n",
      " [9.9625266e-01]\n",
      " [1.2281239e-03]\n",
      " [4.0409177e-06]\n",
      " [6.4921838e-01]\n",
      " [9.3165523e-01]\n",
      " [9.9990106e-01]\n",
      " [9.7943151e-01]\n",
      " [9.9960077e-01]\n",
      " [2.9091329e-09]\n",
      " [1.3721910e-01]\n",
      " [9.9933827e-01]\n",
      " [9.8243630e-01]\n",
      " [1.3208555e-05]\n",
      " [7.8129199e-07]\n",
      " [9.3739474e-01]\n",
      " [9.9789274e-01]\n",
      " [8.2491922e-01]\n",
      " [3.9878488e-04]\n",
      " [1.9232762e-07]\n",
      " [9.9667996e-01]\n",
      " [9.5798182e-01]\n",
      " [1.0459214e-02]\n",
      " [5.4213405e-03]\n",
      " [9.8939180e-01]\n",
      " [6.6129565e-03]\n",
      " [9.9993724e-01]\n",
      " [9.7069633e-01]\n",
      " [9.5179206e-01]\n",
      " [4.7224456e-01]\n",
      " [9.9985731e-01]\n",
      " [9.7365773e-01]\n",
      " [1.2172431e-02]\n",
      " [9.9978548e-01]\n",
      " [1.7402756e-01]\n",
      " [2.5653419e-06]\n",
      " [1.9918323e-02]\n",
      " [5.0259829e-03]\n",
      " [3.8799644e-04]\n",
      " [2.7985871e-03]\n",
      " [9.9825168e-01]\n",
      " [9.8932076e-01]\n",
      " [9.8453677e-01]\n",
      " [5.7158029e-01]\n",
      " [9.5799983e-01]\n",
      " [9.9851477e-01]\n",
      " [9.9850351e-01]\n",
      " [9.9978948e-01]\n",
      " [2.4729388e-05]\n",
      " [3.3917862e-05]\n",
      " [9.9968219e-01]\n",
      " [1.3428032e-03]\n",
      " [1.2196064e-02]\n",
      " [9.9999237e-01]\n",
      " [2.4378300e-04]\n",
      " [2.1730661e-03]\n",
      " [9.8919451e-01]\n",
      " [9.6159625e-01]\n",
      " [9.8689115e-01]\n",
      " [1.6733730e-07]\n",
      " [7.7155149e-01]\n",
      " [9.4289827e-01]\n",
      " [7.0286989e-03]\n",
      " [9.9545503e-01]\n",
      " [5.3356034e-01]\n",
      " [1.1471222e-08]\n",
      " [9.1431046e-01]\n",
      " [1.0669218e-07]\n",
      " [9.9996352e-01]\n",
      " [9.5177054e-01]\n",
      " [9.9988556e-01]\n",
      " [4.4238567e-04]\n",
      " [9.9920917e-01]\n",
      " [9.9782282e-01]\n",
      " [9.8993921e-01]\n",
      " [9.3773007e-04]\n",
      " [8.7641346e-01]\n",
      " [1.4410211e-05]\n",
      " [3.0269623e-03]\n",
      " [9.9793351e-01]\n",
      " [9.9499118e-01]\n",
      " [2.1619915e-05]\n",
      " [2.4089231e-06]\n",
      " [1.8502196e-05]\n",
      " [9.8288727e-01]\n",
      " [9.9541306e-01]\n",
      " [9.7007483e-01]\n",
      " [7.2842240e-03]\n",
      " [6.0469580e-01]\n",
      " [9.8929012e-01]\n",
      " [7.1933746e-01]\n",
      " [5.9958398e-03]\n",
      " [9.9453366e-01]\n",
      " [1.5378047e-06]\n",
      " [9.9986118e-01]\n",
      " [9.9985325e-01]\n",
      " [2.0915031e-02]\n",
      " [9.9547279e-01]\n",
      " [7.7530145e-05]\n",
      " [2.0259657e-05]\n",
      " [3.8390723e-01]\n",
      " [9.9944437e-01]\n",
      " [1.4622870e-01]\n",
      " [9.9959224e-01]\n",
      " [9.9996150e-01]\n",
      " [9.4617045e-01]\n",
      " [9.9689895e-01]\n",
      " [7.4971945e-10]\n",
      " [5.1420927e-04]\n",
      " [9.9991500e-01]\n",
      " [9.8157740e-01]\n",
      " [9.9992299e-01]\n",
      " [9.9999774e-01]\n",
      " [9.9917817e-01]\n",
      " [9.9964416e-01]\n",
      " [9.9270248e-01]\n",
      " [1.7608961e-01]\n",
      " [9.9792778e-01]\n",
      " [9.9757111e-01]\n",
      " [5.9331083e-01]\n",
      " [9.9992847e-01]\n",
      " [2.8966129e-02]\n",
      " [9.4130832e-01]\n",
      " [9.9624085e-01]\n",
      " [9.9674827e-01]\n",
      " [8.9680946e-01]\n",
      " [9.9317598e-01]\n",
      " [9.4527966e-01]\n",
      " [1.8526316e-01]\n",
      " [8.6826420e-01]\n",
      " [9.9597615e-01]\n",
      " [9.6767008e-01]\n",
      " [8.8906920e-01]\n",
      " [9.4070530e-01]\n",
      " [9.9950260e-01]\n",
      " [7.9916149e-02]\n",
      " [4.6063680e-03]\n",
      " [9.8441765e-02]\n",
      " [3.2491350e-01]\n",
      " [8.9075369e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Predicitions\n",
    "\n",
    "\n",
    "predicitions = model.predict(X_test)\n",
    "print(predicitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Rounding and flattening -> get actual predictions\n",
    "\n",
    "predicitions = np.round(predicitions).flatten()\n",
    "print(predicitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 66   1]\n",
      " [  1 120]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predicitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        67\n",
      "           1       0.99      0.99      0.99       121\n",
      "\n",
      "    accuracy                           0.99       188\n",
      "   macro avg       0.99      0.99      0.99       188\n",
      "weighted avg       0.99      0.99      0.99       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predicitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Manual accuracy is: 0.9893617021276596\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0680 - accuracy: 0.9894\n",
      " Assessed accuracy is: [0.06803293526172638, 0.9893617033958435]\n"
     ]
    }
   ],
   "source": [
    "print(f\" Manual accuracy is: {np.mean(predicitions == y_test)}\")\n",
    "print(f\" Assessed accuracy is: {model.evaluate(X_test,y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
